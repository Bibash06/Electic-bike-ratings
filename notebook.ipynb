{"cells":[{"cell_type":"code","execution_count":null,"id":"a78f92f2-07d5-4440-ab49-b818c6c48e63","metadata":{"executionTime":3218,"lastSuccessfullyExecutedCode":"# Necessary cells needed for analysis\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import precision_score,f1_score\nfrom sklearn.preprocessing import LabelEncoder"},"outputs":[],"source":["# Necessary cells needed for analysis\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt \n","import seaborn as sns\n","from sklearn.model_selection import train_test_split,GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import precision_score,f1_score\n","from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"markdown","id":"3f91e3c7-d1af-4b57-b8d2-64da1f470608","metadata":{},"source":["Data Validation\n","\n","This data has 1500 rows and 8 columns.I have validated all variables and made some changes wherever necesary.\n","All the columns are:\n","owned : numeric - 1 or not (0) - two possible outcomes,\n","make_model : character - 6 possible values,\n","review_month : character from Jan to Dec,\n","web_browser : character - 7 categories,\n","reviewer_age : Numeric - from 16 to so on ,\n","primary_use : Character - two categories,\n","value_for_money : rating from 1 to 10,\n","overall_rating : continuous values from  0 to 25"]},{"cell_type":"code","execution_count":null,"id":"d9989281-9feb-48eb-af67-da13ab17b498","metadata":{"executionTime":312,"lastSuccessfullyExecutedCode":"\ndf=pd.read_csv(\"https://s3.amazonaws.com/talent-assets.datacamp.com/electric_bike_ratings_2212.csv\")\n\ndf.head()"},"outputs":[],"source":["\n","df=pd.read_csv(\"https://s3.amazonaws.com/talent-assets.datacamp.com/electric_bike_ratings_2212.csv\")\n","\n","df.head()"]},{"cell_type":"code","execution_count":null,"id":"690b9609-f655-4c25-9158-1aad1945e74f","metadata":{"executionTime":86,"lastSuccessfullyExecutedCode":"df.info()"},"outputs":[],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"id":"4ae53a96-8e3a-495d-8f29-83cada737191","metadata":{"executionTime":76,"lastSuccessfullyExecutedCode":"# Total number of missing values\ndf.isnull().sum()"},"outputs":[],"source":["# Total number of missing values\n","df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"id":"adbaf64d-aee2-4095-8240-a97c9aa32e22","metadata":{"executionTime":72,"lastSuccessfullyExecutedCode":"# validate two possible values\ndf['owned'].unique()"},"outputs":[],"source":["# validate two possible values\n","df['owned'].unique()"]},{"cell_type":"code","execution_count":null,"id":"ba8aa1ec-0eac-4289-897d-7d4eb7f3d64d","metadata":{"executionTime":94,"lastSuccessfullyExecutedCode":"# validate 6 types of models\ndf['make_model'].nunique()"},"outputs":[],"source":["# validate 6 types of models\n","df['make_model'].nunique()"]},{"cell_type":"code","execution_count":null,"id":"8f990ecb-99ea-4565-bd71-71c93cbd7a0e","metadata":{"executionTime":66,"lastSuccessfullyExecutedCode":"# validate month  from Jan to Dec\ndf['review_month'].unique()"},"outputs":[],"source":["# validate month  from Jan to Dec\n","df['review_month'].unique()"]},{"cell_type":"code","execution_count":null,"id":"baf7b503-068f-49ec-adca-3a7eccfbaf53","metadata":{"executionTime":63,"lastSuccessfullyExecutedCode":"# validate 7 types of browser\ndf['web_browser'].unique()"},"outputs":[],"source":["# validate 7 types of browser\n","df['web_browser'].unique()"]},{"cell_type":"code","execution_count":null,"id":"8197173f-461c-405f-9347-93fd252490d2","metadata":{"executionTime":87,"lastSuccessfullyExecutedCode":"# validate age from 16\ndf['reviewer_age'].unique()"},"outputs":[],"source":["# validate age from 16\n","df['reviewer_age'].unique()"]},{"cell_type":"code","execution_count":null,"id":"feb08501-2f05-44c7-8a8c-fff56a5021c8","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# replace '-' variable to avg age in reviewer age column\n\n# Calculate average age for non-null values in the column\navg_age = df.loc[df['reviewer_age'] != '-', 'reviewer_age'].astype(int).mean()\n\n# Replace '-' with average age\ndf['reviewer_age'] = df['reviewer_age'].replace('-', avg_age)\n\n# convert it back to int\ndf['reviewer_age'] = df['reviewer_age'].astype(int)                             "},"outputs":[],"source":["# replace '-' variable to avg age in reviewer age column\n","\n","# Calculate average age for non-null values in the column\n","avg_age = df.loc[df['reviewer_age'] != '-', 'reviewer_age'].astype(int).mean()\n","\n","# Replace '-' with average age\n","df['reviewer_age'] = df['reviewer_age'].replace('-', avg_age)\n","\n","# convert it back to int\n","df['reviewer_age'] = df['reviewer_age'].astype(int)                             "]},{"cell_type":"code","execution_count":null,"id":"cf1907fa-4855-476a-99fe-8d97e3f6ffca","metadata":{"executionTime":61,"lastSuccessfullyExecutedCode":"# validate two user reports\ndf['primary_use'].unique()"},"outputs":[],"source":["# validate two user reports\n","df['primary_use'].unique()"]},{"cell_type":"code","execution_count":null,"id":"7d6f6df5-e945-44ff-b766-286d052f78aa","metadata":{"executionTime":109,"lastSuccessfullyExecutedCode":"# validate ratings from 1 to 10\ndf['value_for_money'].unique()"},"outputs":[],"source":["# validate ratings from 1 to 10\n","df['value_for_money'].unique()"]},{"cell_type":"code","execution_count":null,"id":"143d0ceb-b562-40ae-a795-1ce419bc1229","metadata":{"executionTime":69,"lastSuccessfullyExecutedCode":"# validate total rating score from 0 to 25\ndf['overall_rating'].unique()\n"},"outputs":[],"source":["# validate total rating score from 0 to 25\n","df['overall_rating'].unique()\n"]},{"cell_type":"code","execution_count":null,"id":"fb6a0b59-2081-4dc0-ab88-bcf59c4c4ebf","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Replace the missing value with \"unknown\"\ndf['web_browser'].fillna(\"unknown\",inplace = True)"},"outputs":[],"source":["# Replace the missing value with \"unknown\"\n","df['web_browser'].fillna(\"unknown\",inplace = True)"]},{"cell_type":"code","execution_count":null,"id":"958c8f5a-ea0b-4782-b2d4-bd4ae14cd639","metadata":{"executionTime":78,"lastSuccessfullyExecutedCode":"# Check again if there is any missing value\ndf.isnull().sum()\n"},"outputs":[],"source":["# Check again if there is any missing value\n","df.isnull().sum()\n"]},{"cell_type":"code","execution_count":null,"id":"0c4701e5-5fd9-47e8-ad65-43cc55affbda","metadata":{"executionTime":84,"lastSuccessfullyExecutedCode":"# validate any negative values in numeric variables\ndf.describe()"},"outputs":[],"source":["# validate any negative values in numeric variables\n","df.describe()"]},{"cell_type":"markdown","id":"2ccb89f0-66ca-4955-803b-7820030034ee","metadata":{},"source":[]},{"cell_type":"markdown","id":"4d7e73d5-d804-481d-b7ed-a219aaef2d0d","metadata":{},"source":["Exploratory analysis\n","\n","Target Variable - owned\n","\n","Since,the product team wants to extend the survey. But, they want to be sure they can predict whether the ratings came from owners or non-owners.\n","we use a  barplot visualization to show the number of reviews from owners and non-owners: \n","a->From the visualization, it is clear that the category of the variable \"owned\" with value 1 (or owners) has the most number of observations.\n","b->The observations are not balanced across categories of the variable \"owned\". The number of observations for owners is more than non-owners."]},{"cell_type":"code","execution_count":null,"id":"501009b0-833f-43b0-a1a6-29d0f598945f","metadata":{"executionTime":79,"lastSuccessfullyExecutedCode":"sns.countplot(x='owned', data=df)\nplt.show()"},"outputs":[],"source":["sns.countplot(x='owned', data=df)\n","plt.show()"]},{"cell_type":"markdown","id":"f1be5db6-3da2-4d35-b842-7163731fa7dd","metadata":{},"source":["Looking the histplot below, we can see most of the higher ratings are between 18 to 20."]},{"cell_type":"code","execution_count":null,"id":"c2585c2d-1919-4040-b9c7-d0759aa20f75","metadata":{"executionTime":150,"lastSuccessfullyExecutedCode":"# For distribution of overall rating, we use histogram visualization\n\ndf['overall_rating'].hist()\nplt.xlabel('Overall Rating')\nplt.ylabel('Count')\nplt.title('Distribution of Overall Rating')\nplt.show()\n"},"outputs":[],"source":["# For distribution of overall rating, we use histogram visualization\n","\n","df['overall_rating'].hist()\n","plt.xlabel('Overall Rating')\n","plt.ylabel('Count')\n","plt.title('Distribution of Overall Rating')\n","plt.show()\n"]},{"cell_type":"markdown","id":"321af3df-504c-4b82-8b51-ee2dcb2dbb57","metadata":{},"source":["By looking at below, ownership has higher overallrating than the non ownership.\n","And same goes in web browser and  in primary use,Most of the rater are owner."]},{"cell_type":"code","execution_count":null,"id":"074944a2-f5c5-4d5f-82b0-b7e0afa55755","metadata":{"executionTime":107,"lastSuccessfullyExecutedCode":"# We use a boxplot visualization to show the relationship between ownership and overall rating:\n\nsns.boxplot(x='owned', y='overall_rating', data=df)\nplt.show()\n"},"outputs":[],"source":["# We use a boxplot visualization to show the relationship between ownership and overall rating:\n","\n","sns.boxplot(x='owned', y='overall_rating', data=df)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"35695888-c9e5-4916-a12a-a8a18db51f5a","metadata":{"executionTime":674,"lastSuccessfullyExecutedCode":"# realtionship between ownership and overall rating in websites and acoording to primary uses\n\nfig, axes = plt.subplots(1,2,figsize=(25,6))\n\nsns.boxplot(x='owned', y='overall_rating',hue ='web_browser',data = df,ax=axes[0]).set(title='overall rating in web_browser')\nsns.boxplot(x ='owned',y ='overall_rating',data =df,hue='primary_use',ax=axes[1]).set(title='over all rating according primary use ')\nplt.show()"},"outputs":[],"source":["# realtionship between ownership and overall rating in websites and acoording to primary uses\n","\n","fig, axes = plt.subplots(1,2,figsize=(25,6))\n","\n","sns.boxplot(x='owned', y='overall_rating',hue ='web_browser',data = df,ax=axes[0]).set(title='overall rating in web_browser')\n","sns.boxplot(x ='owned',y ='overall_rating',data =df,hue='primary_use',ax=axes[1]).set(title='over all rating according primary use ')\n","plt.show()"]},{"cell_type":"markdown","id":"eb3df27d-e60d-4172-9586-d5ebdd760a6c","metadata":{},"source":["Model Fitting\n","\n","The business wants to predict whether a review came from an owner or not using the data provided and it is classification tasks\n","so i will use Logistic Regression, it is easy to train and fast to predict and it gives an estimate of the probability of the target variable for each input.\n","For the comparison model i will use Random Forest Classifier ,It can handle missing data and categorical variables, and it is robust to outliers and noisy data. It also gives an estimate of the importance of each feature, which is useful for understanding the dataset.\n"]},{"cell_type":"markdown","id":"f8c6c608-4d2f-464a-a9a6-a6fa938f4c06","metadata":{},"source":["Prepare Data for Modelling\n","\n","To enable modelling, we chose make_model, review_month,web_browser,reviewer_age,primary_use, value_for_money as features, owned as target variables.\n","I also have made the following changes:\n","\n","Convert the categorical variables into numeric features and\n","Split the data into a training set and a test set"]},{"cell_type":"code","execution_count":null,"id":"ce96e7ff-b5c0-47b2-812c-15d16e6a9147","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Split dataset into 80% training set and 20% test set\nX = df[['make_model', 'review_month', 'web_browser', 'reviewer_age', 'primary_use',\n        'value_for_money']]\ny = df['owned']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"},"outputs":[],"source":["# Split dataset into 80% training set and 20% test set\n","X = df[['make_model', 'review_month', 'web_browser', 'reviewer_age', 'primary_use',\n","        'value_for_money']]\n","y = df['owned']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":null,"id":"5bf1d303-6cfc-4433-bf55-19d38a157fb1","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# converting into numerical variable\nencoder = LabelEncoder()\ndf['make_model'] = encoder.fit_transform(df['make_model'])\ndf['review_month'] = encoder.fit_transform(df['review_month'])\ndf['web_browser'] = encoder.fit_transform(df['web_browser'])\ndf['primary_use'] = encoder.fit_transform(df['primary_use'])\ndf['value_for_money'] = encoder.fit_transform(df['value_for_money'])\n"},"outputs":[],"source":["# converting into numerical variable\n","encoder = LabelEncoder()\n","df['make_model'] = encoder.fit_transform(df['make_model'])\n","df['review_month'] = encoder.fit_transform(df['review_month'])\n","df['web_browser'] = encoder.fit_transform(df['web_browser'])\n","df['primary_use'] = encoder.fit_transform(df['primary_use'])\n","df['value_for_money'] = encoder.fit_transform(df['value_for_money'])\n"]},{"cell_type":"markdown","id":"c5b654bf-1bc9-4a6d-a378-65ea95d2958f","metadata":{},"source":["Logistic Regeression"]},{"cell_type":"code","execution_count":null,"id":"76b4446c-9c17-4aa7-8119-8d33c51a6593","metadata":{"collapsed":false,"executionTime":99,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastSuccessfullyExecutedCode":"log_reg = LogisticRegression( C = 0.1 , penalty = 'l2')\nlog_reg.fit(X_train, y_train)\ny_pred_log_reg = log_reg.predict(X_test)\n# Calculate the f1_score\nf1 = f1_score(y_test, y_pred_log_reg)\nprint(\"F1 Score:\", f1)\n# Calculate the precision_score\nprecision = precision_score(y_test, y_pred_log_reg)\nprint(\"Precision Score:\", precision) "},"outputs":[],"source":["log_reg = LogisticRegression( C = 0.1 , penalty = 'l2')\n","log_reg.fit(X_train, y_train)\n","y_pred_log_reg = log_reg.predict(X_test)\n","# Calculate the f1_score\n","f1 = f1_score(y_test, y_pred_log_reg)\n","print(\"F1 Score:\", f1)\n","# Calculate the precision_score\n","precision = precision_score(y_test, y_pred_log_reg)\n","print(\"Precision Score:\", precision) "]},{"cell_type":"markdown","id":"8b46c19f-9f40-4a90-9de9-e014f1ad694f","metadata":{},"source":["Finding the feature importance"]},{"cell_type":"code","execution_count":null,"id":"0f21be51-d6d7-49ff-9863-7d50d753290e","metadata":{"collapsed":false,"executionTime":192,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastSuccessfullyExecutedCode":"# Train the logistic regression model\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\n\n# Get the feature importances\ncoefs = log_reg.coef_[0]\n\n# Create a list of feature names\nfeature_names = X.columns\n\n# Create a dataframe of feature importances\nfeature_importances = pd.DataFrame({'feature': feature_names, 'coef': coefs})\n\n# Sort the dataframe by feature importance\nfeature_importances.sort_values(by='coef', ascending=False, inplace=True)\n\n# Print the feature importances\nprint(feature_importances)\n"},"outputs":[],"source":["# Train the logistic regression model\n","log_reg = LogisticRegression()\n","log_reg.fit(X_train, y_train)\n","\n","# Get the feature importances\n","coefs = log_reg.coef_[0]\n","\n","# Create a list of feature names\n","feature_names = X.columns\n","\n","# Create a dataframe of feature importances\n","feature_importances = pd.DataFrame({'feature': feature_names, 'coef': coefs})\n","\n","# Sort the dataframe by feature importance\n","feature_importances.sort_values(by='coef', ascending=False, inplace=True)\n","\n","# Print the feature importances\n","print(feature_importances)\n"]},{"cell_type":"code","execution_count":null,"id":"3ef233fc-6896-4676-bf6f-598fd4675031","metadata":{"executionCancelledAt":1675130063802},"outputs":[],"source":["# Plot the feature importances\n","plt.bar(feature_importances['feature'], feature_importances['coef'])\n","plt.xlabel('Feature')\n","plt.ylabel('Coefficient')\n","plt.title('Feature Importances')\n","plt.xticks(rotation=90)\n","plt.show()"]},{"cell_type":"markdown","id":"8a0aaf35-d39d-4014-8d95-7320e9b9d381","metadata":{},"source":["Finding the best parameters"]},{"cell_type":"code","execution_count":null,"id":"5408feca-c281-479d-b4ce-65ae7411403d","metadata":{"executionCancelledAt":1675130064027},"outputs":[],"source":["# Define the parameter grid\n","param_grid = {'C': [0.1, 1, 10],\n","              'penalty': ['l1', 'l2']}\n","\n","# Create the grid search object\n","grid_search = GridSearchCV(log_reg, param_grid, cv=5, n_jobs=-1)\n","\n","# Fit the grid search to the data\n","grid_search.fit(X_train, y_train)\n","\n","# Print the best parameters and the best score\n","print(\"Best parameters: \", grid_search.best_params_)\n","print(\"Best score: \", grid_search.best_score_)\n"]},{"cell_type":"code","execution_count":null,"id":"c5c75b51-de72-4756-9dd7-60d743595a76","metadata":{"executionCancelledAt":1675130064125},"outputs":[],"source":["# visulizing it \n","# Get the results of the grid search\n","results = grid_search.cv_results_\n","\n","# Extract the mean test score for each combination of parameters\n","scores = results['mean_test_score'].reshape(len(param_grid['C']), len(param_grid['penalty']))\n","\n","# Create a heatmap of the test scores\n","plt.imshow(scores, cmap='gray', interpolation='nearest')\n","plt.colorbar()\n","plt.xlabel('Penalty')\n","plt.ylabel('C')\n","plt.xticks(np.arange(len(param_grid['penalty'])), param_grid['penalty'])\n","plt.yticks(np.arange(len(param_grid['C'])), param_grid['C'])\n","plt.title('Accuracy of Logistic Regression')\n","plt.show()"]},{"cell_type":"markdown","id":"849c054a-87a2-4a5f-96e2-ec5355ea258b","metadata":{},"source":["Random Forest Classifier"]},{"cell_type":"code","execution_count":null,"id":"3d5953c8-9f51-426c-a597-b41bd742e4d1","metadata":{"collapsed":false,"executionTime":353,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastSuccessfullyExecutedCode":"\nrnd_clf = RandomForestClassifier(n_estimators = 200 , max_depth = 5)\nrnd_clf.fit(X_train, y_train)\n\ny_pred_rnd_clf = rnd_clf.predict(X_test)\n\nf1 = f1_score(y_test, y_pred_rnd_clf)\nprint(\"F1 Score:\", f1)\n# Calculate the precision_score\nprecision = precision_score(y_test, y_pred_rnd_clf)\nprint(\"Precision Score:\", precision) "},"outputs":[],"source":["\n","rnd_clf = RandomForestClassifier(n_estimators = 200 , max_depth = 5)\n","rnd_clf.fit(X_train, y_train)\n","\n","y_pred_rnd_clf = rnd_clf.predict(X_test)\n","\n","f1 = f1_score(y_test, y_pred_rnd_clf)\n","print(\"F1 Score:\", f1)\n","# Calculate the precision_score\n","precision = precision_score(y_test, y_pred_rnd_clf)\n","print(\"Precision Score:\", precision) "]},{"cell_type":"markdown","id":"365e5e77-ccf6-4708-82bc-c892ff6cd349","metadata":{},"source":["Finding the feature importance"]},{"cell_type":"code","execution_count":null,"id":"84b7ba4f-8e3a-4105-b8d2-565608ed513e","metadata":{"executionTime":221,"lastSuccessfullyExecutedCode":"# Train the random forest classifier\nrnd_clf = RandomForestClassifier()\nrnd_clf.fit(X_train, y_train)\n\n# Get the feature importances\nimportances = rnd_clf.feature_importances_\n\n# Create a list of feature names\nfeature_names = X.columns\n\n# Create a dataframe of feature importances\nfeature_importances = pd.DataFrame({'feature': feature_names, 'importance': importances})\n\n# Sort the dataframe by feature importance\nfeature_importances.sort_values(by='importance', ascending=False, inplace=True)\n\n# Print the feature importances\nprint(feature_importances)"},"outputs":[],"source":["# Train the random forest classifier\n","rnd_clf = RandomForestClassifier()\n","rnd_clf.fit(X_train, y_train)\n","\n","# Get the feature importances\n","importances = rnd_clf.feature_importances_\n","\n","# Create a list of feature names\n","feature_names = X.columns\n","\n","# Create a dataframe of feature importances\n","feature_importances = pd.DataFrame({'feature': feature_names, 'importance': importances})\n","\n","# Sort the dataframe by feature importance\n","feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n","\n","# Print the feature importances\n","print(feature_importances)"]},{"cell_type":"code","execution_count":null,"id":"4a74861b-85f5-4985-8aa2-b749267f3370","metadata":{"executionTime":458,"lastSuccessfullyExecutedCode":"# Plot the feature importances\nplt.bar(feature_importances['feature'], feature_importances['importance'])\nplt.xlabel('Feature')\nplt.ylabel('Importance')\nplt.title('Feature Importances')\nplt.xticks(rotation=90)\nplt.show()"},"outputs":[],"source":["# Plot the feature importances\n","plt.bar(feature_importances['feature'], feature_importances['importance'])\n","plt.xlabel('Feature')\n","plt.ylabel('Importance')\n","plt.title('Feature Importances')\n","plt.xticks(rotation=90)\n","plt.show()"]},{"cell_type":"markdown","id":"2f5193e9-6c03-48fd-9a12-780076c45353","metadata":{},"source":["Finding the best parameter"]},{"cell_type":"code","execution_count":null,"id":"e5df2490-c3f0-4a4c-8e9e-7ab6fc0a785c","metadata":{"executionTime":8193,"lastSuccessfullyExecutedCode":"# Define the parameter grid\nparam_grid = {'n_estimators': [100, 200, 300],\n              'max_depth': [5, 10, 15] }\n\n# Create the grid search object\ngrid_search = GridSearchCV(rnd_clf, param_grid, cv=5, n_jobs=-1)\n\n# Fit the grid search to the data\ngrid_search.fit(X_train, y_train)\n\n# Print the best parameters and the best score\nprint(\"Best parameters: \", grid_search.best_params_)\nprint(\"Best score: \", grid_search.best_score_)\n"},"outputs":[],"source":["# Define the parameter grid\n","param_grid = {'n_estimators': [100, 200, 300],\n","              'max_depth': [5, 10, 15] }\n","\n","# Create the grid search object\n","grid_search = GridSearchCV(rnd_clf, param_grid, cv=5, n_jobs=-1)\n","\n","# Fit the grid search to the data\n","grid_search.fit(X_train, y_train)\n","\n","# Print the best parameters and the best score\n","print(\"Best parameters: \", grid_search.best_params_)\n","print(\"Best score: \", grid_search.best_score_)\n"]},{"cell_type":"code","execution_count":null,"id":"d84468a9-cfeb-469e-bc00-db515d609764","metadata":{"executionTime":458,"lastSuccessfullyExecutedCode":"# visulizing it\n\n# Extract the results of the grid search\nresults = grid_search.cv_results_\n\n# Extract the mean test scores\nmean_test_scores = results['mean_test_score']\n\n# Extract the standard deviation of the test scores\nstd_test_scores = results['std_test_score']\n\n# Extract the parameters that were tested\nparams = results['params']\n\n# Plot the mean test scores\nplt.errorbar(range(len(params)), mean_test_scores, yerr=std_test_scores)\nplt.xlabel('Parameter Combination')\nplt.ylabel('Mean Test Score')\nplt.show()\n"},"outputs":[],"source":["# visulizing it\n","\n","# Extract the results of the grid search\n","results = grid_search.cv_results_\n","\n","# Extract the mean test scores\n","mean_test_scores = results['mean_test_score']\n","\n","# Extract the standard deviation of the test scores\n","std_test_scores = results['std_test_score']\n","\n","# Extract the parameters that were tested\n","params = results['params']\n","\n","# Plot the mean test scores\n","plt.errorbar(range(len(params)), mean_test_scores, yerr=std_test_scores)\n","plt.xlabel('Parameter Combination')\n","plt.ylabel('Mean Test Score')\n","plt.show()\n"]},{"cell_type":"markdown","id":"ff5be578-ee6d-4252-a51e-1c45d204062c","metadata":{},"source":["This above  plot  shows the mean test score for each parameter combination tested in the grid search, along with the standard deviation of the test scores. The x-axis shows the index of the parameter combination, and the y-axis shows the mean test score."]},{"cell_type":"markdown","id":"a922e80b-b46b-4f0e-89ae-e6d11522067e","metadata":{},"source":["why i choose them to be my evaluation?\n","\n","the precision_score metric  focus on the model's ability to correctly predict the positive class, specifically minimizing the number of false positives.\n","It ranges between 0 and 1, where 1 represents a perfect score and 0 represents a poor score.Precision is a measure of how many of the positive predictions were actually correct.\n","\n","f1_score metric balance precision and recall and get a single number that\n","represents the overall performance of the model.\n","It ranges between 0 and 1, where 1 represents a perfect score and 0 represents a poor score.\n"," F1 score is a better measure than accuracy, especially if you have \n"," an uneven class distribution."]},{"cell_type":"markdown","id":"76e612d6-588d-40f0-8746-66099d427815","metadata":{},"source":["The f1_score of the Logistic Regression model and Decision Tree model is  0.76 and 0.80, meaning that Random Forest Classification model predicts more correctly than Logistic Regression \n","And Precision_score of Logistic Regression and Random Forest Classification is 0.71 and 0.75,meaning that Random Forest Classification is considered better performing model.\n","\n","From this metric, we can conclude that the Random Forest classification  model has a higher chance of performing better."]}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}
